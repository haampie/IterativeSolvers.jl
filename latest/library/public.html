<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public · IterativeSolvers.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>IterativeSolvers.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><a class="toctext" href="../user_manual.html">Manual</a></li><li><span class="toctext">Linear systems</span><ul><li><a class="toctext" href="cg.html">Conjugate Gradients</a></li><li><a class="toctext" href="chebyshev.html">Chebyshev iteration</a></li><li><a class="toctext" href="minres.html">MINRES</a></li><li><a class="toctext" href="bicgstabl.html">BiCGStab(l)</a></li><li><a class="toctext" href="gmres.html">Restarted GMRES</a></li><li><a class="toctext" href="stationary.html">Stationary methods</a></li></ul></li><li><span class="toctext">Eigenproblems</span><ul><li><a class="toctext" href="power_method.html">Power method</a></li></ul></li><li><a class="toctext" href="../preconditioning.html">Preconditioning</a></li><li><span class="toctext">Library</span><ul><li class="current"><a class="toctext" href="public.html">Public</a><ul class="internal"><li><a class="toctext" href="#Index-1">Index</a></li><li><a class="toctext" href="#Linear-Solvers-1">Linear Solvers</a></li><li><a class="toctext" href="#Eigen-Solvers-1">Eigen Solvers</a></li><li><a class="toctext" href="#Randomized-1">Randomized</a></li><li><a class="toctext" href="#Types-1">Types</a></li></ul></li><li><a class="toctext" href="internal.html">Internal</a></li></ul></li><li><span class="toctext">About</span><ul><li><a class="toctext" href="../about/CONTRIBUTING.html">Contributing</a></li><li><a class="toctext" href="../about/license.html">License</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Library</li><li><a href="public.html">Public</a></li></ul><a class="edit-page" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/docs/src/library/public.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Public</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Iterative-methods-1" href="#Iterative-methods-1">Iterative methods</a></h1><p>Documentation for <code>IterativeSolvers.jl</code>&#39;s public interface.</p><ul><li><a href="public.html#Iterative-methods-1">Iterative methods</a></li><ul><li><a href="public.html#Index-1">Index</a></li><li><a href="public.html#Linear-Solvers-1">Linear Solvers</a></li><ul><li><a href="public.html#IDR(s)-1">IDR(s)</a></li><li><a href="public.html#LSMR-1">LSMR</a></li><li><a href="public.html#LSQR-1">LSQR</a></li></ul><li><a href="public.html#Eigen-Solvers-1">Eigen Solvers</a></li><ul><li><a href="public.html#Golub-Kahan-Lanczos-1">Golub-Kahan-Lanczos</a></li></ul><li><a href="public.html#Randomized-1">Randomized</a></li><ul><li><a href="public.html#Condition-number-estimate-1">Condition number estimate</a></li><li><a href="public.html#Extremal-eigenvalue-estimates-1">Extremal eigenvalue estimates</a></li><li><a href="public.html#Norm-estimate-1">Norm estimate</a></li><li><a href="public.html#Randomized-singular-value-decomposition-1">Randomized singular value decomposition</a></li></ul><li><a href="public.html#Types-1">Types</a></li><ul><li><a href="public.html#ConvergenceHistory-1"><code>ConvergenceHistory</code></a></li></ul></ul></ul><h2><a class="nav-anchor" id="Index-1" href="#Index-1">Index</a></h2><ul><li><a href="public.html#IterativeSolvers.ConvergenceHistory"><code>IterativeSolvers.ConvergenceHistory</code></a></li><li><a href="public.html#IterativeSolvers.idrs"><code>IterativeSolvers.idrs</code></a></li><li><a href="public.html#IterativeSolvers.idrs!"><code>IterativeSolvers.idrs!</code></a></li><li><a href="public.html#IterativeSolvers.lsmr"><code>IterativeSolvers.lsmr</code></a></li><li><a href="public.html#IterativeSolvers.lsmr!"><code>IterativeSolvers.lsmr!</code></a></li><li><a href="public.html#IterativeSolvers.lsqr"><code>IterativeSolvers.lsqr</code></a></li><li><a href="public.html#IterativeSolvers.lsqr!"><code>IterativeSolvers.lsqr!</code></a></li><li><a href="public.html#IterativeSolvers.rcond"><code>IterativeSolvers.rcond</code></a></li><li><a href="public.html#IterativeSolvers.reig"><code>IterativeSolvers.reig</code></a></li><li><a href="public.html#IterativeSolvers.reigmax"><code>IterativeSolvers.reigmax</code></a></li><li><a href="public.html#IterativeSolvers.reigmin"><code>IterativeSolvers.reigmin</code></a></li><li><a href="public.html#IterativeSolvers.rnorm"><code>IterativeSolvers.rnorm</code></a></li><li><a href="public.html#IterativeSolvers.rnorms"><code>IterativeSolvers.rnorms</code></a></li><li><a href="public.html#IterativeSolvers.rsvd_fnkz"><code>IterativeSolvers.rsvd_fnkz</code></a></li><li><a href="public.html#IterativeSolvers.rsvdfact"><code>IterativeSolvers.rsvdfact</code></a></li><li><a href="public.html#IterativeSolvers.svdl"><code>IterativeSolvers.svdl</code></a></li></ul><h2><a class="nav-anchor" id="Linear-Solvers-1" href="#Linear-Solvers-1">Linear Solvers</a></h2><h3><a class="nav-anchor" id="IDR(s)-1" href="#IDR(s)-1">IDR(s)</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.idrs" href="#IterativeSolvers.idrs"><code>IterativeSolvers.idrs</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">idrs(A, b)</code></pre><p>Solve A*x=b using the induced dimension reduction method.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>x, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>x</code>.</p><p><strong>Arguments</strong></p><p><code>A</code>: linear operator.</p><p><code>b</code>: right hand side.</p><p><strong>Keywords</strong></p><p><code>Pl = 1</code>: left preconditioner of the method.</p><p><code>Pr = 1</code>: right preconditioner of the method.</p><p><code>tol::Real = sqrt(eps())</code>: stopping tolerance.</p><p><code>restart::Integer = min(20,length(b))</code>: maximum number of iterations per restart.</p><p><code>maxiter::Integer = min(20,length(b))</code>: maximum number of iterations.</p><p><code>verbose::Bool = false</code>: print method information.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>x</code>: approximated solution.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>x</code>: approximated solution.</p><p><code>ch</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:tol</code> =&gt; <code>::Real</code>: stopping tolerance.</p><p><code>:resnom</code> =&gt; <code>::Vector</code>: residual norm at each iteration.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/idrs.jl#L199-L250">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.idrs!" href="#IterativeSolvers.idrs!"><code>IterativeSolvers.idrs!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">idrs!(x, A, b)</code></pre><p>Overwrite <code>x</code>.</p><p>Solve A*x=b using the induced dimension reduction method.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>x, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>x</code>.</p><p><strong>Arguments</strong></p><p><code>x</code>: initial guess, overwrite final estimation.</p><p><code>A</code>: linear operator.</p><p><code>b</code>: right hand side.</p><p><strong>Keywords</strong></p><p><code>Pl = 1</code>: left preconditioner of the method.</p><p><code>Pr = 1</code>: right preconditioner of the method.</p><p><code>tol::Real = sqrt(eps())</code>: stopping tolerance.</p><p><code>restart::Integer = min(20,length(b))</code>: maximum number of iterations per restart.</p><p><code>maxiter::Integer = min(20,length(b))</code>: maximum number of iterations.</p><p><code>verbose::Bool = false</code>: print method information.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>x</code>: approximated solution.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>x</code>: approximated solution.</p><p><code>ch</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:tol</code> =&gt; <code>::Real</code>: stopping tolerance.</p><p><code>:resnom</code> =&gt; <code>::Vector</code>: residual norm at each iteration.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/idrs.jl#L199-L252">source</a><br/></section><p><strong>References</strong></p><pre><code class="language-none">[1] IDR(s): a family of simple and fast algorithms for solving large
    nonsymmetric linear systems. P. Sonneveld and M. B. van Gijzen
    SIAM J. Sci. Comput. Vol. 31, No. 2, pp. 1035--1062, 2008
[2] Algorithm 913: An Elegant IDR(s) Variant that Efficiently Exploits
    Bi-orthogonality Properties. M. B. van Gijzen and P. Sonneveld
    ACM Trans. Math. Software,, Vol. 38, No. 1, pp. 5:1-5:19, 2011
[3] This file is a translation of the following MATLAB implementation:
    http://ta.twi.tudelft.nl/nw/users/gijzen/idrs.m
[4] IDR(s)&#39; webpage http://ta.twi.tudelft.nl/nw/users/gijzen/IDR.html</code></pre><h3><a class="nav-anchor" id="LSMR-1" href="#LSMR-1">LSMR</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.lsmr" href="#IterativeSolvers.lsmr"><code>IterativeSolvers.lsmr</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">lsmr(A, b)</code></pre><p>Minimize ||Ax-b||^2 + λ^2 ||x||^2 for A*x=b.</p><p>The method is based on the Golub-Kahan bidiagonalization process. It is algebraically equivalent to applying MINRES to the normal equation (ATA+λ2I)x=ATb, but has better numerical properties, especially if A is ill-conditioned.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>x, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>x</code>.</p><p><strong>Arguments</strong></p><p><code>A</code>: linear operator.</p><p><code>b</code>: right hand side.</p><p><strong>Keywords</strong></p><p><code>λ::Number = 0</code>: lambda.</p><p><code>atol::Number = 1e-6</code>, <code>btol::Number = 1e-6</code>: stopping tolerances. If both are 1.0e-9 (say), the final residual norm should be accurate to about 9 digits. (The final <code>x</code> will usually have fewer correct digits, depending on <code>cond(A)</code> and the size of damp).</p><p><code>conlim::Number = 1e8</code>: stopping tolerance.  <code>lsmr</code> terminates if an estimate of <code>cond(A)</code> exceeds conlim.  For compatible systems Ax = b, conlim could be as large as 1.0e+12 (say).  For least-squares problems, conlim should be less than 1.0e+8. Maximum precision can be obtained by setting <code>atol</code> = <code>btol</code> = <code>conlim</code> = zero, but the number of iterations may then be excessive.</p><p><code>maxiter::Integer = min(20,length(b))</code>: maximum number of iterations.</p><p><code>verbose::Bool = false</code>: print method information.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>x</code>: approximated solution.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>x</code>: approximated solution.</p><p><code>ch</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:atol</code> =&gt; <code>::Real</code>: atol stopping tolerance.</p><p><code>:btol</code> =&gt; <code>::Real</code>: btol stopping tolerance.</p><p><code>:ctol</code> =&gt; <code>::Real</code>: ctol stopping tolerance.</p><p><code>:anorm</code> =&gt; <code>::Real</code>: anorm.</p><p><code>:rnorm</code> =&gt; <code>::Real</code>: rnorm.</p><p><code>:cnorm</code> =&gt; <code>::Real</code>: cnorm.</p><p><code>:resnom</code> =&gt; <code>::Vector</code>: residual norm at each iteration.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/lsmr.jl#L240-L314">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.lsmr!" href="#IterativeSolvers.lsmr!"><code>IterativeSolvers.lsmr!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">lsmr!(x, A, b)</code></pre><p>Overwrite <code>x</code>.</p><p>Minimize ||Ax-b||^2 + λ^2 ||x||^2 for A*x=b.</p><p>The method is based on the Golub-Kahan bidiagonalization process. It is algebraically equivalent to applying MINRES to the normal equation (ATA+λ2I)x=ATb, but has better numerical properties, especially if A is ill-conditioned.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>x, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>x</code>.</p><p><strong>Arguments</strong></p><p><code>x</code>: initial guess, overwrite final estimation.</p><p><code>A</code>: linear operator.</p><p><code>b</code>: right hand side.</p><p><strong>Keywords</strong></p><p><code>λ::Number = 0</code>: lambda.</p><p><code>atol::Number = 1e-6</code>, <code>btol::Number = 1e-6</code>: stopping tolerances. If both are 1.0e-9 (say), the final residual norm should be accurate to about 9 digits. (The final <code>x</code> will usually have fewer correct digits, depending on <code>cond(A)</code> and the size of damp).</p><p><code>conlim::Number = 1e8</code>: stopping tolerance.  <code>lsmr</code> terminates if an estimate of <code>cond(A)</code> exceeds conlim.  For compatible systems Ax = b, conlim could be as large as 1.0e+12 (say).  For least-squares problems, conlim should be less than 1.0e+8. Maximum precision can be obtained by setting <code>atol</code> = <code>btol</code> = <code>conlim</code> = zero, but the number of iterations may then be excessive.</p><p><code>maxiter::Integer = min(20,length(b))</code>: maximum number of iterations.</p><p><code>verbose::Bool = false</code>: print method information.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>x</code>: approximated solution.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>x</code>: approximated solution.</p><p><code>ch</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:atol</code> =&gt; <code>::Real</code>: atol stopping tolerance.</p><p><code>:btol</code> =&gt; <code>::Real</code>: btol stopping tolerance.</p><p><code>:ctol</code> =&gt; <code>::Real</code>: ctol stopping tolerance.</p><p><code>:anorm</code> =&gt; <code>::Real</code>: anorm.</p><p><code>:rnorm</code> =&gt; <code>::Real</code>: rnorm.</p><p><code>:cnorm</code> =&gt; <code>::Real</code>: cnorm.</p><p><code>:resnom</code> =&gt; <code>::Vector</code>: residual norm at each iteration.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/lsmr.jl#L240-L316">source</a><br/></section><p><strong>References</strong></p><p>Adapted from: <a href="http://web.stanford.edu/group/SOL/software/lsmr/">http://web.stanford.edu/group/SOL/software/lsmr/</a></p><h3><a class="nav-anchor" id="LSQR-1" href="#LSQR-1">LSQR</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.lsqr" href="#IterativeSolvers.lsqr"><code>IterativeSolvers.lsqr</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">lsqr(A, b)</code></pre><p>LSQR solves Ax = b or min ||b - Ax||^2 if damp = 0, or   min ||(b) - (  A   )x||   otherwise.          ||(0)   (damp*I) ||^2.</p><p>The method is based on the Golub-Kahan bidiagonalization process. It is algebraically equivalent to applying CG to the normal equation (ATA+λ2I)x=ATb, but has better numerical properties, especially if A is ill-conditioned.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>x, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>x</code>.</p><p><strong>Arguments</strong></p><p><code>A</code>: linear operator.</p><p><code>b</code>: right hand side.</p><p><strong>Keywords</strong></p><p><code>damp::Number = 0</code>: damping parameter.</p><p><code>atol::Number = 1e-6</code>, <code>btol::Number = 1e-6</code>: stopping tolerances. If both are 1.0e-9 (say), the final residual norm should be accurate to about 9 digits. (The final <code>x</code> will usually have fewer correct digits, depending on <code>cond(A)</code> and the size of damp).</p><p><code>conlim::Number = 1e8</code>: stopping tolerance.  <code>lsmr</code> terminates if an estimate of <code>cond(A)</code> exceeds conlim.  For compatible systems Ax = b, conlim could be as large as 1.0e+12 (say).  For least-squares problems, conlim should be less than 1.0e+8. Maximum precision can be obtained by setting <code>atol</code> = <code>btol</code> = <code>conlim</code> = zero, but the number of iterations may then be excessive.</p><p><code>maxiter::Integer = min(20,length(b))</code>: maximum number of iterations.</p><p><code>verbose::Bool = false</code>: print method information.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>x</code>: approximated solution.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>x</code>: approximated solution.</p><p><code>ch</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:atol</code> =&gt; <code>::Real</code>: atol stopping tolerance.</p><p><code>:btol</code> =&gt; <code>::Real</code>: btol stopping tolerance.</p><p><code>:ctol</code> =&gt; <code>::Real</code>: ctol stopping tolerance.</p><p><code>:anorm</code> =&gt; <code>::Real</code>: anorm.</p><p><code>:rnorm</code> =&gt; <code>::Real</code>: rnorm.</p><p><code>:cnorm</code> =&gt; <code>::Real</code>: cnorm.</p><p><code>:resnom</code> =&gt; <code>::Vector</code>: residual norm at each iteration.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/lsqr.jl#L225-L301">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.lsqr!" href="#IterativeSolvers.lsqr!"><code>IterativeSolvers.lsqr!</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">lsqr!(x, A, b)</code></pre><p>Overwrite <code>x</code>.</p><p>LSQR solves Ax = b or min ||b - Ax||^2 if damp = 0, or   min ||(b) - (  A   )x||   otherwise.          ||(0)   (damp*I) ||^2.</p><p>The method is based on the Golub-Kahan bidiagonalization process. It is algebraically equivalent to applying CG to the normal equation (ATA+λ2I)x=ATb, but has better numerical properties, especially if A is ill-conditioned.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>x, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>x</code>.</p><p><strong>Arguments</strong></p><p><code>x</code>: initial guess, overwrite final estimation.</p><p><code>A</code>: linear operator.</p><p><code>b</code>: right hand side.</p><p><strong>Keywords</strong></p><p><code>damp::Number = 0</code>: damping parameter.</p><p><code>atol::Number = 1e-6</code>, <code>btol::Number = 1e-6</code>: stopping tolerances. If both are 1.0e-9 (say), the final residual norm should be accurate to about 9 digits. (The final <code>x</code> will usually have fewer correct digits, depending on <code>cond(A)</code> and the size of damp).</p><p><code>conlim::Number = 1e8</code>: stopping tolerance.  <code>lsmr</code> terminates if an estimate of <code>cond(A)</code> exceeds conlim.  For compatible systems Ax = b, conlim could be as large as 1.0e+12 (say).  For least-squares problems, conlim should be less than 1.0e+8. Maximum precision can be obtained by setting <code>atol</code> = <code>btol</code> = <code>conlim</code> = zero, but the number of iterations may then be excessive.</p><p><code>maxiter::Integer = min(20,length(b))</code>: maximum number of iterations.</p><p><code>verbose::Bool = false</code>: print method information.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>x</code>: approximated solution.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>x</code>: approximated solution.</p><p><code>ch</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:atol</code> =&gt; <code>::Real</code>: atol stopping tolerance.</p><p><code>:btol</code> =&gt; <code>::Real</code>: btol stopping tolerance.</p><p><code>:ctol</code> =&gt; <code>::Real</code>: ctol stopping tolerance.</p><p><code>:anorm</code> =&gt; <code>::Real</code>: anorm.</p><p><code>:rnorm</code> =&gt; <code>::Real</code>: rnorm.</p><p><code>:cnorm</code> =&gt; <code>::Real</code>: cnorm.</p><p><code>:resnom</code> =&gt; <code>::Vector</code>: residual norm at each iteration.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/lsqr.jl#L225-L303">source</a><br/></section><p><strong>References</strong></p><pre><code class="language-none">Adapted from: http://web.stanford.edu/group/SOL/software/lsqr/

1. C. C. Paige and M. A. Saunders (1982a).
    LSQR: An algorithm for sparse linear equations and sparse least squares,
    ACM TOMS 8(1), 43-71.

2. C. C. Paige and M. A. Saunders (1982b).
    Algorithm 583.  LSQR: Sparse linear equations and least squares problems,
    ACM TOMS 8(2), 195-209.

3. M. A. Saunders (1995).  Solution of sparse rectangular systems using
    LSQR and CRAIG, BIT 35, 588-604.</code></pre><h2><a class="nav-anchor" id="Eigen-Solvers-1" href="#Eigen-Solvers-1">Eigen Solvers</a></h2><h3><a class="nav-anchor" id="Golub-Kahan-Lanczos-1" href="#Golub-Kahan-Lanczos-1">Golub-Kahan-Lanczos</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.svdl" href="#IterativeSolvers.svdl"><code>IterativeSolvers.svdl</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">svdl(A)</code></pre><p>Compute some singular values (and optionally vectors) using Golub-Kahan-Lanczos bidiagonalization \cite{Golub1965} with thick restarting \cite{Wu2000}.</p><p>If <code>log</code> is set to <code>true</code> is given, method will output a tuple <code>X, L, ch</code>. Where <code>ch</code> is a <code>ConvergenceHistory</code> object. Otherwise it will only return <code>X, L</code>.</p><p><strong>Arguments</strong></p><p><code>A</code> : The matrix or matrix-like object whose singular values are desired.</p><p><strong>Keywords</strong></p><p><code>nsv::Int = 6</code>: number of singular values requested.</p><p><code>v0 = random unit vector</code>: starting guess vector in the domain of <code>A</code>. The length of <code>q</code> should be the number of columns in <code>A</code>.</p><p><code>k::Int = 2nsv</code>: maximum number of Lanczos vectors to compute before restarting.</p><p><code>j::Int = nsv</code>: number of vectors to keep at the end of the restart. We don&#39;t recommend j &lt; nsv.</p><p><code>maxiter::Int = minimum(size(A))</code>: maximum number of iterations to run.</p><p><code>verbose::Bool = false</code>: print information at each iteration.</p><p><code>tol::Real = √eps()</code>: maximum absolute error in each desired singular value.</p><p><code>reltol::Real=√eps()</code>: maximum error in each desired singular value relative to the estimated norm of the input matrix.</p><p><code>method::Symbol=:ritz</code>: restarting algorithm to use. Valid choices are:</p><ul><li><p><code>:ritz</code>: Thick restart with Ritz values [Wu2000].</p></li><li><p><code>:harmonic</code>: Restart with harmonic Ritz values [Baglama2005].</p></li></ul><p><code>vecs::Symbol = :none</code>: singular vectors to return.</p><ul><li><p><code>:both</code>: Both left and right singular vectors are returned.</p></li><li><p><code>:left</code>: Only the left singular vectors are returned.</p></li><li><p><code>:right</code>: Only the right singular vectors are returned.</p></li><li><p><code>:none</code>: No singular vectors are returned.</p></li></ul><p><code>dolock::Bool=false</code>: If <code>true</code>, locks converged Ritz values, removing them from the Krylov subspace being searched in the next macroiteration.</p><p><code>log::Bool = false</code>: output an extra element of type <code>ConvergenceHistory</code> containing extra information of the method execution.</p><p><strong>Output</strong></p><p><strong>if <code>log</code> is <code>false</code></strong></p><p><code>Σ</code>: list of the desired singular values if <code>vecs == :none</code> (the default), otherwise returns an <code>SVD</code> object with the desired singular vectors filled in.</p><p><code>L</code>: computed partial factorizations of A.</p><p><strong>if <code>log</code> is <code>true</code></strong></p><p><code>Σ</code>: list of the desired singular values if <code>vecs == :none</code> (the default), otherwise returns an <code>SVD</code> object with the desired singular vectors filled in.</p><p><code>L</code>: computed partial factorizations of A.</p><p><code>ch::ConvergenceHistory</code>: convergence history.</p><p><strong>ConvergenceHistory keys</strong></p><p><code>:betas</code> =&gt; <code>betas</code>: The history of the computed betas.</p><p><code>:Bs</code> =&gt; <code>Bs</code>: The history of the computed projected matrices.</p><p><code>:ritz</code> =&gt; <code>ritzvalhist</code>: Ritz values computed at each iteration.</p><p><code>:conv</code> =&gt; <code>convhist</code>: Convergence data.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/svdl.jl#L85-L165">source</a><br/></section><p><strong>Implementation notes</strong></p><p>The implementation of thick restarting follows closely that of SLEPc as described in [Hernandez2008]. Thick restarting can be turned off by setting <code>k = maxiter</code>, but most of the time this is not desirable.</p><p>The singular vectors are computed directly by forming the Ritz vectors from the product of the Lanczos vectors <code>L.P</code>/<code>L.Q</code> and the singular vectors of <code>L.B</code>. Additional accuracy in the singular triples can be obtained using inverse iteration.</p><p><strong>References</strong></p><pre><code class="language-bibtex">@article{Golub1965,
    author = {Golub, G. and Kahan, W.},
    doi = {10.1137/0702016},
    journal = {Journal of the Society for Industrial and Applied Mathematics
        Series B Numerical Analysis},
    volume = 2,
    number = 2,
    pages = {205--224},
    title = {Calculating the Singular Values and Pseudo-Inverse of a Matrix},
    year = 1965
}

@article{Wu2000,
    author = {Wu, Kesheng and Simon, Horst},
    journal = {SIAM Journal on Matrix Analysis and Applications},
    number = 2,
    pages = {602--616},
    title = {Thick-Restart {L}anczos Method for Large Symmetric Eigenvalue Problems},
    volume = 22,
    year = 2000
}

@article{Baglama2005,
    author = {Baglama, James and Reichel, Lothar},
    doi = {10.1137/04060593X},
    journal = {SIAM Journal on Scientific Computing},
    number = 1,
    pages = {19--42},
    title = {Augmented Implicitly Restarted {L}anczos Bidiagonalization Methods},
    volume = 27,
    year = 2005
}

@article{Hernandez2008,
    author = {Hern\&#39;{a}ndez, Vicente and Rom\&#39;{a}n, Jos\&#39;{e} E and Tom\&#39;{a}s,
    Andr\&#39;{e}s},
    journal = {Electronic Transactions on Numerical Analysis},
    pages = {68--85},
    title = {A Robust and Efficient Parallel {SVD} Solver based on Restarted
        {L}anczos Bidiagonalization},
    url = {http://etna.mcs.kent.edu/volumes/2001-2010/vol31/abstract.php?vol=31\&amp;pages=68-85},
    volume = 31,
    year = 2008
}</code></pre><h2><a class="nav-anchor" id="Randomized-1" href="#Randomized-1">Randomized</a></h2><h3><a class="nav-anchor" id="Condition-number-estimate-1" href="#Condition-number-estimate-1">Condition number estimate</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.rcond" href="#IterativeSolvers.rcond"><code>IterativeSolvers.rcond</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">rcond(A, iters=1)</code></pre><p>Estimate matrix condition number randomly.</p><p><strong>Arguments</strong></p><p><code>A</code>: matrix whose condition number to estimate. Must be square and support premultiply (<code>A*⋅</code>) and solve (<code>A\⋅</code>).</p><p><code>iters::Int = 1</code>: number of power iterations to run.</p><p><strong>Keywords</strong></p><p><code>p::Real = 0.05</code>: probability that estimate fails to hold as an upper bound.</p><p><strong>Output</strong></p><p>Interval <code>(x, y)</code> which contains <code>κ(A)</code> with probability <code>1 - p</code>.</p><p><strong>Implementation note</strong></p><p>\cite{Dixon1983} originally describes this as a computation that can be done by computing the necessary number of power iterations given p and the desired accuracy parameter <code>θ=y/x</code>. However, these bounds were only derived under the assumptions of exact arithmetic. Empirically, <code>iters≥4</code> has been seen to result in incorrect results in that the computed interval does not contain the true condition number. This implemention therefore makes <code>iters</code> an explicitly user-controllable parameter from which to infer the accuracy parameter and hence the interval containing <code>κ(A)</code>.</p><p><strong>References</strong></p><p>\cite[Theorem 2]{Dixon1983}</p><pre><code class="language-bibtex">@article{Dixon1983,
    author = {Dixon, John D},
    doi = {10.1137/0720053},
    journal = {SIAM Journal on Numerical Analysis},
    number = {4},
    pages = {812--814},
    title = {Estimating Extremal Eigenvalues and Condition Numbers of
	Matrices},
    volume = {20},
    year = {1983}
}</code></pre></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rlinalg.jl#L172-L220">source</a><br/></section><h3><a class="nav-anchor" id="Extremal-eigenvalue-estimates-1" href="#Extremal-eigenvalue-estimates-1">Extremal eigenvalue estimates</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.reigmin" href="#IterativeSolvers.reigmin"><code>IterativeSolvers.reigmin</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">reigmin(A, iters=1)</code></pre><p>Estimate minimal eigenvalue randomly.</p><p><strong>Arguments</strong></p><p><code>A</code>: Matrix whose maximal eigenvalue to estimate. Must be square and support premultiply (<code>A*⋅</code>).</p><p><code>iters::Int=1</code>: Number of power iterations to run. (Recommended: <code>iters</code> ≤ 3)</p><p><strong>Keywords</strong></p><p><code>p::Real=0.05</code>: Probability that estimate fails to hold as an upper bound.</p><p><strong>Output</strong></p><p>Interval <code>(x, y)</code> which contains the maximal eigenvalue of <code>A</code> with probability <code>1 - p</code>.</p><p><strong>References</strong></p><p>\cite[Corollary of Theorem 1]{Dixon1983}.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rlinalg.jl#L276-L300">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.reigmax" href="#IterativeSolvers.reigmax"><code>IterativeSolvers.reigmax</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">reigmax(A, iters=1)</code></pre><p>Estimate maximal eigenvalue randomly.</p><p><strong>Arguments</strong></p><p><code>A</code>: Matrix whose maximal eigenvalue to estimate. Must be square and support premultiply (<code>A*⋅</code>).</p><p><code>iters::Int=1</code>: Number of power iterations to run. (Recommended: <code>iters</code> ≤ 3)</p><p><strong>Keywords</strong></p><p><code>p::Real=0.05</code>: Probability that estimate fails to hold as an upper bound.</p><p><strong>Output</strong></p><p>Interval <code>(x, y)</code> which contains the maximal eigenvalue of <code>A</code> with probability <code>1 - p</code>.</p><p><strong>References</strong></p><p>\cite[Corollary of Theorem 1]{Dixon1983}.</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rlinalg.jl#L238-L262">source</a><br/></section><h3><a class="nav-anchor" id="Norm-estimate-1" href="#Norm-estimate-1">Norm estimate</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.rnorm" href="#IterativeSolvers.rnorm"><code>IterativeSolvers.rnorm</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">rnorm(A, mvps)</code></pre><p>Compute a probabilistic upper bound on the norm of a matrix <code>A</code>. <code>‖A‖ ≤ α √(2/π) maxᵢ ‖Aωᵢ‖</code> with probability <code>p=α^(-mvps)</code>.</p><p><strong>Arguments</strong></p><p><code>A</code>: matrix whose norm to estimate.</p><p><code>mvps::Int</code>: number of matrix-vector products to compute.</p><p><strong>Keywords</strong></p><p><code>p::Real=0.05</code>: probability of upper bound failing.</p><p><strong>Output</strong></p><p>Estimate of ‖A‖.</p><p><strong>See also</strong></p><p>see <a href="public.html#IterativeSolvers.rnorms"><code>rnorms</code></a> for a different estimator that uses premultiplying by both <code>A</code> and <code>A&#39;</code>.</p><p><strong>References</strong></p><p>\cite[Lemma 4.1]{Halko2011}</p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rlinalg.jl#L64-L92">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.rnorms" href="#IterativeSolvers.rnorms"><code>IterativeSolvers.rnorms</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">rnorms(A, iters=1)</code></pre><p>Estimate matrix norm randomly using <code>A&#39;A</code>.</p><p>Compute a probabilistic upper bound on the norm of a matrix <code>A</code>.</p><pre><code class="language-none">ρ = √(‖(A&#39;A)ʲω‖/‖(A&#39;A)ʲ⁻¹ω‖)</code></pre><p>which is an estimate of the spectral norm of <code>A</code> produced by <code>iters</code> steps of the power method starting with normalized <code>ω</code>, is a lower bound on the true norm by a factor</p><pre><code class="language-none">ρ ≤ α ‖A‖</code></pre><p>with probability greater than <code>1 - p</code>, where <code>p = 4\sqrt(n/(iters-1)) α^(-2iters)</code>.</p><p><strong>Arguments</strong></p><p><code>A</code>: matrix whose norm to estimate.</p><p><code>iters::Int = 1</code>: mumber of power iterations to perform.</p><p><strong>Keywords</strong></p><p><code>p::Real = 0.05</code>: probability of upper bound failing.</p><p><code>At = A&#39;</code>: Transpose of <code>A</code>.</p><p><strong>Output</strong></p><p>Estimate of ‖A‖.</p><p><strong>See also</strong></p><p>see <a href="public.html#IterativeSolvers.rnorm"><code>rnorm</code></a> for a different estimator that does not require premultiplying by <code>A&#39;</code></p><p><strong>References</strong></p><p>Appendix of \cite{Liberty2007}.</p><pre><code class="language-bibtex">@article{Liberty2007,
    authors = {Edo Liberty and Franco Woolfe and Per-Gunnar Martinsson
    and Vladimir Rokhlin and Mark Tygert},
    title = {Randomized algorithms for the low-rank approximation of matrices},
    journal = {Proceedings of the National Academy of Sciences},
    volume = {104},
    issue = {51},
    year = {2007},
    pages = {20167--20172},
    doi  = {10.1073/pnas.0709640104}
}</code></pre></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rlinalg.jl#L103-L158">source</a><br/></section><h3><a class="nav-anchor" id="Randomized-singular-value-decomposition-1" href="#Randomized-singular-value-decomposition-1">Randomized singular value decomposition</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.reig" href="#IterativeSolvers.reig"><code>IterativeSolvers.reig</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">reig(A, l)</code></pre><p>Compute the spectral (<code>Eigen</code>) decomposition of <code>A</code> using a randomized algorithm.</p><p><strong>Arguments</strong></p><p><code>A</code>: input matrix.</p><p><code>l::Int</code>: number of eigenpairs to find.</p><p><strong>Output</strong></p><p><code>::Base.LinAlg.Eigen</code>: eigen decomposition.</p><p><strong>Implementation note</strong></p><p>This is a wrapper around <code>eigfact_onepass()</code> which uses the randomized samples found using <code>srft(l)</code>.</p><p><strong>References</strong></p><pre><code class="language-bibtex">@article{Halko2011,
    author = {Halko, N and Martinsson, P G and Tropp, J A},
    doi = {10.1137/090771806},
    journal = {SIAM Review},
    month = jan,
    number = {2},
    pages = {217--288},
    title = {Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions},
    volume = {53},
    year = {2011}
}</code></pre></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rsvd.jl#L557-L593">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.rsvdfact" href="#IterativeSolvers.rsvdfact"><code>IterativeSolvers.rsvdfact</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">rsvdfact(A, n, p=0)</code></pre><p>Compute partial singular value decomposition of <code>A</code> using a randomized algorithm.</p><p><strong>Arguments</strong></p><p><code>A</code>: input matrix.</p><p><code>n::Int</code>: number of singular value/vector pairs to find.</p><p><code>p::Int=0</code>: number of extra vectors to include in computation.</p><p><strong>Output</strong></p><p><code>::SVD</code>: singular value decomposition.</p><p><strong>Warning</strong></p><p>This variant of the randomized singular value decomposition is the most commonly found implementation but is not recommended for accurate computations, as it often has trouble finding the <code>n</code> largest singular pairs, but rather finds <code>n</code> large singular pairs which may not necessarily be the largest.</p><p><strong>Implementation note</strong></p><p>This function calls <code>rrange</code>, which uses naive randomized rangefinding to compute a basis for a subspace of dimension <code>n</code> (Algorithm 4.1 of \cite{Halko2011}), followed by <code>svdfact_restricted()</code>, which computes the exact SVD factorization on the restriction of <code>A</code> to this randomly selected subspace (Algorithm 5.1 of \cite{Halko2011}).</p><p>Alternatively, you can mix and match your own randomized algorithm using any of the randomized range finding algorithms to find a suitable subspace and feeding the result to one of the routines that computes the <code>SVD</code> restricted to that subspace.</p><p><strong>References</strong></p><pre><code class="language-bibtex">@article{Halko2011,
    author = {Halko, N and Martinsson, P G and Tropp, J A},
    doi = {10.1137/090771806},
    journal = {SIAM Review},
    month = jan,
    number = {2},
    pages = {217--288},
    title = {Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions},
    volume = {53},
    year = {2011}
}</code></pre></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rsvd.jl#L13-L67">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.rsvd_fnkz" href="#IterativeSolvers.rsvd_fnkz"><code>IterativeSolvers.rsvd_fnkz</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">rsvd_fnkz(A, k)</code></pre><p>Compute the randomized SVD by iterative refinement from randomly selected columns/rows.</p><p><strong>Arguments</strong></p><p><code>A</code>: matrix whose SVD is desired.</p><p><code>k::Int</code>: desired rank of approximation (<code>k ≤ min(m, n)</code>).</p><p><strong>Keywords</strong></p><p><code>l::Int = k</code>: number of columns/rows to sample at each iteration (<code>1 ≤ l ≤ k</code>).</p><p><code>N::Int = minimum(size(A))</code>: maximum number of iterations.</p><p><code>ϵ::Real = prod(size(A))*eps()</code>: relative threshold for convergence, as measured by growth of the spectral norm.</p><p><code>method::Symbol = :eig</code>: problem to solve.</p><ul><li><p><code>:eig</code>: eigenproblem.</p></li><li><p><code>:svd</code>: singular problem.</p></li></ul><p><code>verbose::Bool = false</code>: print convergence information at each iteration.</p><p><strong>Output</strong></p><p>SVD object of <code>rank ≤ k</code>.</p><p><strong>References</strong></p><pre><code class="language-bibtex">@inproceedings{,
    author={Friedland, S. and Niknejad, A. and Kaveh, Mostafa and Zare, H.},
    booktitle={System of Systems Engineering, 2006 IEEE/SMC International Conference on},
    title={Fast Monte-Carlo low rank approximations for matrices},
    year={2006},
    month={April},
    pages={218--223},
    doi={10.1109/SYSOSE.2006.1652299}
}</code></pre></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/rsvd_fnkz.jl#L11-L55">source</a><br/></section><h2><a class="nav-anchor" id="Types-1" href="#Types-1">Types</a></h2><h3><a class="nav-anchor" id="ConvergenceHistory-1" href="#ConvergenceHistory-1"><code>ConvergenceHistory</code></a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="IterativeSolvers.ConvergenceHistory" href="#IterativeSolvers.ConvergenceHistory"><code>IterativeSolvers.ConvergenceHistory</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Store general and in-depth information about an iterative method.</p><p><strong>Fields</strong></p><p><code>mvps::Int</code>: number of matrix vector products.</p><p><code>mtvps::Int</code>: number of transposed matrix-vector products</p><p><code>iters::Int</code>: iterations taken by the method.</p><p><code>restart::T</code>: restart relevant information.</p><ul><li><p><code>T == Int</code>: iterations per restart.</p></li><li><p><code>T == Void</code>: methods without restarts.</p></li></ul><p><code>isconverged::Bool</code>: convergence of the method.</p><p><code>data::Dict{Symbol,Any}</code>: Stores all the information stored during the method execution. It stores tolerances, residuals and other information, e.g. ritz values in <a href="library/@ref">svdl</a>.</p><p><strong>Constructors</strong></p><pre><code class="language-none">ConvergenceHistory()
ConvergenceHistory(restart)</code></pre><p>Create <code>ConvergenceHistory</code> with empty fields.</p><p><strong>Arguments</strong></p><p><code>restart</code>: number of iterations per restart.</p><p><strong>Plots</strong></p><p>Supports plots using the <code>Plots.jl</code> package via a type recipe. Vectors are ploted as series and matrices as scatterplots.</p><p><strong>Implements</strong></p><p><code>Base</code>: <code>getindex</code>, <code>setindex!</code>, <code>push!</code></p></div><a class="source-link" target="_blank" href="https://github.com/haampie/IterativeSolvers.jl/tree/94c62f8fbfd4e30978d0973ce76b9076342346a2/src/history.jl#L12-L53">source</a><br/></section><footer><hr/><a class="previous" href="../preconditioning.html"><span class="direction">Previous</span><span class="title">Preconditioning</span></a><a class="next" href="internal.html"><span class="direction">Next</span><span class="title">Internal</span></a></footer></article></body></html>
